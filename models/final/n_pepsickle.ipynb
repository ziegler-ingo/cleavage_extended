{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7befc08-6896-4d94-90b6-4b9c097ada8c",
   "metadata": {},
   "source": [
    "# Sources\n",
    "* Customised implementation of the journal article:\n",
    "    * pepsickle rapidly and accurately predicts proteasomal cleavage sites for improved neoantigen identification\n",
    "    * Benjamin R Weeder, Mary A Wood, Ellysia Li, Abhinav Nellore, Reid F Thompson\n",
    "    * https://academic.oup.com/bioinformatics/article/37/21/3723/6363787\n",
    "    * https://github.com/pdxgx/pepsickle\n",
    "    * https://github.com/pdxgx/pepsickle-paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d232386-9a7a-49bf-92fb-cd945373b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5693ab8-25f5-43b4-96f2-45a692cfaad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f048d06b-424d-4895-a3cc-d5968b69b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, \"r\") as csvfile:\n",
    "        train_data = list(csv.reader(csvfile))[1:]  # skip col name\n",
    "        sents, lbls = [], []\n",
    "        for s, l in train_data:\n",
    "            sents.append(s)\n",
    "            lbls.append(l)\n",
    "    return sents, lbls\n",
    "\n",
    "\n",
    "def regularized_auc(train_auc, dev_auc, threshold=0.0025):\n",
    "    \"\"\"\n",
    "    Returns development AUC if overfitting is below threshold, otherwise 0.\n",
    "    \"\"\"\n",
    "    return dev_auc if (train_auc - dev_auc) < threshold else 0\n",
    "\n",
    "\n",
    "def save_metrics(*args, path):\n",
    "    if not os.path.isfile(path):\n",
    "        with open(path, \"w\", newline=\"\\n\") as f:\n",
    "            f.write(\n",
    "                \",\".join(\n",
    "                    [\n",
    "                        \"fold\",\n",
    "                        \"epoch\",\n",
    "                        \"seq_train_loss\",\n",
    "                        \"motif_train_loss\",\n",
    "                        \"seq_train_acc\",\n",
    "                        \"motif_train_acc\",\n",
    "                        \"combined_train_acc\",\n",
    "                        \"seq_train_auc\",\n",
    "                        \"motif_train_auc\",\n",
    "                        \"combined_train_auc\",\n",
    "                        \"seq_val_loss\",\n",
    "                        \"motif_val_loss\",\n",
    "                        \"seq_val_acc\",\n",
    "                        \"motif_val_acc\",\n",
    "                        \"combined_val_acc\",\n",
    "                        \"seq_val_auc\",\n",
    "                        \"motif_val_auc\",\n",
    "                        \"combined_val_auc\",\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            f.write(\"\\n\")\n",
    "    if args:\n",
    "        with open(path, \"a\", newline=\"\\n\") as f:\n",
    "            f.write(\",\".join([str(arg) for arg in args]))\n",
    "            f.write(\"\\n\")  \n",
    "            \n",
    "def trainable_model_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def total_model_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ae9a12-fd5d-4cba-87f4-015a72f44dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleavageDataset(Dataset):\n",
    "    def __init__(self, seq, lbl):\n",
    "        self.seq = seq\n",
    "        self.lbl = lbl\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.seq[idx], self.lbl[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lbl)\n",
    "\n",
    "\n",
    "class Batch:\n",
    "    def __init__(self, batch):\n",
    "        ordered_batch = list(zip(*batch))\n",
    "        self.seq = torch.tensor(\n",
    "            [\n",
    "                [_features[aa] for aa in list(seq)]\n",
    "                for seq in ordered_batch[0]\n",
    "            ],\n",
    "            dtype=torch.float,\n",
    "        )\n",
    "        self.lbl = torch.tensor([int(l) for l in ordered_batch[1]], dtype=torch.float)\n",
    "\n",
    "    def pin_memory(self):\n",
    "        self.seq = self.seq.pin_memory()\n",
    "        self.lbl = self.lbl.pin_memory()\n",
    "        return self\n",
    "\n",
    "\n",
    "def collate_wrapper(batch):\n",
    "    return Batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "935ceaa1-fa0a-4885-a1c8-373aa89cd7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architectures taken from \n",
    "# https://github.com/pdxgx/pepsickle-paper/blob/master/scripts/modeling/epitope_based_ensemble_net.py\n",
    "\n",
    "class SeqNet(nn.Module):\n",
    "    def __init__(self, hidden_size1, hidden_size2, hidden_size3, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # input to linear: seq_len * 20\n",
    "        self.fc1 = nn.Linear(200, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, 1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size2)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_size3)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        out = self.dropout(F.relu(self.bn1(self.fc1(seq))))\n",
    "        out = self.dropout(F.relu(self.bn2(self.fc2(out))))\n",
    "        out = self.dropout(F.relu(self.bn3(self.fc3(out))))\n",
    "        return self.fc4(out).squeeze()\n",
    "    \n",
    "    \n",
    "class MotifNet(nn.Module):\n",
    "    def __init__(self, hidden_size1, hidden_size2, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # conv parameters are fixed due to feature assemply process\n",
    "        # see dictionary variable _features\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=4,\n",
    "            out_channels=4,\n",
    "            kernel_size=3,\n",
    "            groups=4\n",
    "        )\n",
    "    \n",
    "        # input to linear: groups * (seq_len-2)\n",
    "        self.fc1 = nn.Linear(32, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, 1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size2)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        out = self.conv(seq.transpose(1, 2))\n",
    "        \n",
    "        out = self.dropout(F.relu(self.bn1(self.fc1(out.view(out.shape[0], -1)))))\n",
    "        out = self.dropout(F.relu(self.bn2(self.fc2(out))))\n",
    "        return self.fc3(out).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64c6f8e4-903e-4d00-acb8-5b92b83b5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(seq_model, motif_model, loader, criterion, optims=None):\n",
    "    seq_epoch_loss, seq_num_correct, num_correct, total = 0, 0, 0, 0\n",
    "    motif_epoch_loss, motif_num_correct = 0, 0\n",
    "    seq_preds, motif_preds, preds, lbls = [], [], [], []\n",
    "    \n",
    "    for batch in tqdm(\n",
    "        loader,\n",
    "        desc=\"Train: \" if optims is not None else \"Eval: \",\n",
    "        file=sys.stdout,\n",
    "        unit=\"batches\"\n",
    "    ):\n",
    "        seq, lbl = batch.seq, batch.lbl\n",
    "        seq, lbl = seq.to(device), lbl.to(device)\n",
    "         \n",
    "        motif_scores = motif_model(seq[:, :, 22:])\n",
    "        seq_scores = seq_model(seq[:, :, :20].reshape(seq.shape[0], -1))\n",
    "        scores = (motif_scores + seq_scores) / 2\n",
    "            \n",
    "        motif_loss = criterion(motif_scores, lbl)\n",
    "        seq_loss = criterion(seq_scores, lbl)\n",
    "        \n",
    "        if optims is not None:\n",
    "            optims[0].zero_grad()\n",
    "            seq_loss.backward()\n",
    "            optims[0].step()\n",
    "            optims[1].zero_grad()\n",
    "            motif_loss.backward()\n",
    "            optims[1].step()\n",
    "        \n",
    "        seq_epoch_loss += seq_loss.item()\n",
    "        motif_epoch_loss += motif_loss.item()\n",
    "        seq_num_correct += ((seq_scores > 0) == lbl).sum().item()\n",
    "        motif_num_correct += ((motif_scores > 0) == lbl).sum().item()\n",
    "        num_correct += ((scores > 0) == lbl).sum().item()\n",
    "        total += seq.shape[0]\n",
    "        seq_preds.extend(seq_scores.detach().tolist())\n",
    "        motif_preds.extend(motif_scores.detach().tolist())\n",
    "        preds.extend(scores.detach().tolist())\n",
    "        lbls.extend(lbl.detach().tolist())\n",
    "        \n",
    "    return [\n",
    "        seq_epoch_loss / total,\n",
    "        motif_epoch_loss / total,\n",
    "        seq_num_correct / total,\n",
    "        motif_num_correct / total,\n",
    "        num_correct / total,\n",
    "        roc_auc_score(lbls, seq_preds),\n",
    "        roc_auc_score(lbls, motif_preds),\n",
    "        roc_auc_score(lbls, preds)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40d19cf-10cd-4720-a0db-9a2ac26c5890",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# load train+dev set, mix it back as one\n",
    "train_path = '../../data/n_train.csv'\n",
    "dev_path = '../../data/n_val.csv'\n",
    "test_path = '../../data/n_test.csv'\n",
    "\n",
    "# combine previously split train and dev set\n",
    "train_seqs, train_lbls = read_data(train_path)\n",
    "dev_seqs, dev_lbls = read_data(dev_path)\n",
    "total_seqs, total_lbls = np.array(train_seqs + dev_seqs), np.array(train_lbls + dev_lbls)\n",
    "\n",
    "assert len(train_seqs) + len(dev_seqs) == len(total_seqs)\n",
    "assert len(train_lbls) + len(dev_lbls) == len(total_lbls)\n",
    "\n",
    "test_seqs, test_lbls = read_data(test_path)\n",
    "\n",
    "test_data = CleavageDataset(test_seqs, test_lbls)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, collate_fn=collate_wrapper, pin_memory=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c06799a-5bdf-4de3-81fd-4f039bb4a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://github.com/pdxgx/pepsickle README for more info\n",
    "\n",
    "_features = {\n",
    "    'A': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,      6.0, 56.15265,   -0.495,  -2.4],\n",
    "    'C': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     5.07, 69.61701,    0.081,  -4.7],\n",
    "    'D': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     2.77, 70.04515,    9.573,  -4.5],\n",
    "    'E': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     3.22, 86.35615,    3.173,  -5.2],\n",
    "    'F': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   1,   0,     5.48,  119.722,   -0.370,  -4.9],\n",
    "    'G': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     5.97, 37.80307,    0.386,  -1.9],\n",
    "    'H': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   1,   0,     7.59, 97.94236,    2.029,  -4.4],\n",
    "    'I': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     6.02, 103.6644,   -0.528,  -6.6],\n",
    "    'K': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     9.74, 102.7783,    2.101,  -7.5],\n",
    "    'L': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     5.98, 102.7545,   -0.342,  -6.3],\n",
    "    'M': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     5.74,  103.928,   -0.324,  -6.1],\n",
    "    'N': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     5.41, 76.56687,    2.354,  -4.7],\n",
    "    'P': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,   0,   0,      6.3, 71.24858,   -0.322,  -0.8],\n",
    "    'Q': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,   0,   0,     5.65, 88.62562,    2.176,  -5.5],\n",
    "    'R': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,   0,   0,    10.76, 110.5867,    4.383,  -6.9],\n",
    "    'S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,   0,   1,     5.68, 55.89516,    0.936,  -4.6],\n",
    "    'T': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,   0,   1,      5.6,  72.0909,    0.853,  -5.1],\n",
    "    'V': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,   0,   0,     5.96, 86.28358,   -0.308,  -4.6],\n",
    "    'W': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,   1,   0,     5.89, 137.5186,    -0.27,  -4.8],\n",
    "    'Y': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,   1,   1,     5.66, 121.5862,    1.677,  -5.4],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c675854d-18d4-45e3-a20f-725c8a737f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "motif_params = {\n",
    "    \"hidden_size1\": 200,\n",
    "    \"hidden_size2\": 23,\n",
    "    \"dropout\": 0.12\n",
    "}\n",
    "\n",
    "seq_params = {\n",
    "    \"hidden_size1\": 175,\n",
    "    \"hidden_size2\": 96,\n",
    "    \"hidden_size3\": 44,\n",
    "    \"dropout\": 0.32\n",
    "}\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53c23c7-7cc5-4b98-bf26-c40133bad399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "path = \"../../params/n_term/pepsickle/\"\n",
    "logging_path = path + \"results.csv\"\n",
    "\n",
    "start = time()\n",
    "print(\"Starting Cross-Validation.\")\n",
    "highest_val_auc = 0\n",
    "\n",
    "# get a new split\n",
    "for fold, (train_idx, dev_idx) in enumerate(kf.split(total_seqs), 1):\n",
    "    X_tr = total_seqs[train_idx]\n",
    "    y_tr = total_lbls[train_idx]\n",
    "    X_dev = total_seqs[dev_idx]\n",
    "    y_dev = total_lbls[dev_idx]\n",
    "\n",
    "    # create datasets and loads with current split\n",
    "    train_data = CleavageDataset(X_tr, y_tr)\n",
    "    train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_wrapper,\n",
    "        pin_memory=True,\n",
    "        num_workers=10,\n",
    "    )\n",
    "\n",
    "    dev_data = CleavageDataset(X_dev, y_dev)\n",
    "    dev_loader = DataLoader(\n",
    "        dev_data,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_wrapper,\n",
    "        pin_memory=True,\n",
    "        num_workers=10,\n",
    "    )\n",
    "\n",
    "    # reset model weights with each new fold\n",
    "    motif_model = MotifNet(**motif_params).to(device)\n",
    "    seq_model = SeqNet(**seq_params).to(device)\n",
    "    motif_optimizer = optim.Adam(motif_model.parameters(), lr=1e-3)\n",
    "    seq_optimizer = optim.Adam(seq_model.parameters(), lr=1e-3)\n",
    "\n",
    "    # normal training loop\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        seq_model.train()\n",
    "        motif_model.train()\n",
    "        train_results = process(\n",
    "            seq_model,\n",
    "            motif_model,\n",
    "            train_loader,\n",
    "            criterion,\n",
    "            [seq_optimizer, motif_optimizer],\n",
    "        )\n",
    "\n",
    "        seq_model.eval()\n",
    "        motif_model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_results = process(seq_model, motif_model, dev_loader, criterion)\n",
    "\n",
    "        results = train_results + val_results\n",
    "        # save metrics\n",
    "        save_metrics(\n",
    "            fold,\n",
    "            epoch,\n",
    "            *results,\n",
    "            path=logging_path,\n",
    "        )\n",
    "\n",
    "        if (\n",
    "            regularized_auc(train_results[5], val_results[5], threshold=0)\n",
    "            and regularized_auc(train_results[6], val_results[6], threshold=0)\n",
    "            and val_results[7] > highest_val_auc\n",
    "        ):\n",
    "            highest_val_auc = val_results[7]\n",
    "            seq_path = path + f\"auc{val_results[7]:.4f}_fold{fold}_epoch{epoch}_seq.pt\"\n",
    "            motif_path = (\n",
    "                path + f\"auc{val_results[7]:.4f}_fold{fold}_epoch{epoch}_motif.pt\"\n",
    "            )\n",
    "            torch.save(seq_model.state_dict(), seq_path)\n",
    "            torch.save(motif_model.state_dict(), motif_path)\n",
    "\n",
    "print(\"Finished Cross-Validation.\")\n",
    "train_time = (time() - start) / 60\n",
    "print(f\"Cross-Validation took {train_time} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2effd87-a492-4632-92cb-145d1e16b13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded auc0.7883_fold3_epoch10_seq.pt and auc0.7883_fold3_epoch10_motif.pt\n",
      "Eval: 100%|██████████████████████████████████████████████████████| 281/281 [00:00<00:00, 321.81batches/s]\n",
      "Test Set Performance: Acc: 0.8318, AUC: 0.7888\n",
      "Seq: Total model params: 57014, trainable model params: 57014\n",
      "Motif: Total model params: 11709, trainable model params: 11709\n"
     ]
    }
   ],
   "source": [
    "# load best model, evaluate on test set\n",
    "seq_best_model = sorted(\n",
    "    [f for f in os.listdir(path) if f.endswith(\"seq.pt\")],\n",
    "    reverse=True,\n",
    ")[0]\n",
    "motif_best_model = sorted(\n",
    "    [f for f in os.listdir(path) if f.endswith(\"motif.pt\")],\n",
    "    reverse=True,\n",
    ")[0]\n",
    "\n",
    "print(f'Loaded {seq_best_model} and {motif_best_model}')\n",
    "\n",
    "motif_model = MotifNet(**motif_params).to(device)\n",
    "seq_model = SeqNet(**seq_params).to(device)\n",
    "seq_model.load_state_dict(torch.load(path + seq_best_model))\n",
    "motif_model.load_state_dict(torch.load(path + motif_best_model))\n",
    "\n",
    "seq_model.eval()\n",
    "motif_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_results = process(seq_model, motif_model, test_loader, criterion)\n",
    "print(\n",
    "    f\"Test Set Performance: Acc: {test_results[4]:.4f}, AUC: {test_results[7]:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Seq: Total model params: {total_model_params(seq_model)}, trainable model params: {trainable_model_params(seq_model)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Motif: Total model params: {total_model_params(motif_model)}, trainable model params: {trainable_model_params(motif_model)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df4eb0-6596-4938-b139-a22516e8db66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

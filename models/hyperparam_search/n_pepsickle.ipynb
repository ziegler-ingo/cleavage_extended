{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f02ffd0-2cc4-4b48-b43c-101d8c39b2a5",
   "metadata": {},
   "source": [
    "# Sources\n",
    "* Customised implementation of the journal article:\n",
    "    * pepsickle rapidly and accurately predicts proteasomal cleavage sites for improved neoantigen identification\n",
    "    * Benjamin R Weeder, Mary A Wood, Ellysia Li, Abhinav Nellore, Reid F Thompson\n",
    "    * https://academic.oup.com/bioinformatics/article/37/21/3723/6363787\n",
    "    * https://github.com/pdxgx/pepsickle\n",
    "    * https://github.com/pdxgx/pepsickle-paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded39806-fc83-4b0c-b9ce-14e896a4675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbbe232-2c39-49c6-9187-a80c6812d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e449b96d-6e11-4b72-a5e6-8f20c1b71115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, 'r') as csvfile:\n",
    "        train_data = list(csv.reader(csvfile))[1:] # skip col name\n",
    "        sents, lbls = [], []\n",
    "        for s, l in train_data:\n",
    "            sents.append(s)\n",
    "            lbls.append(l)\n",
    "    return sents, lbls\n",
    "\n",
    "def regularized_auc(train_auc, dev_auc, threshold=0.0025):\n",
    "    \"\"\"\n",
    "    Returns development AUC if overfitting is below threshold, otherwise 0.\n",
    "    \"\"\"\n",
    "    return dev_auc if (train_auc - dev_auc) < threshold else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e97d7b-5a80-4637-9dc2-13137fda75c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleavageDataset(Dataset):\n",
    "    def __init__(self, seq, lbl):\n",
    "        self.seq = seq\n",
    "        self.lbl = lbl\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.seq[idx], self.lbl[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lbl)\n",
    "    \n",
    "def collate_batch(batch):\n",
    "    ordered_batch = list(zip(*batch))\n",
    "    seq = torch.tensor(\n",
    "        [\n",
    "            [_features[aa] for aa in list(seq)]\n",
    "            for seq in ordered_batch[0]\n",
    "        ],\n",
    "        dtype=torch.float,\n",
    "    )\n",
    "    lbl = torch.tensor([int(l) for l in ordered_batch[1]], dtype=torch.float)\n",
    "    return seq, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4cc48e7-1186-4391-b9d8-924eee98b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architectures taken from \n",
    "# https://github.com/pdxgx/pepsickle-paper/blob/master/scripts/modeling/epitope_based_ensemble_net.py\n",
    "\n",
    "class SeqNet(nn.Module):\n",
    "    def __init__(self, hidden_size1, hidden_size2, hidden_size3, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # input to linear: seq_len * 20\n",
    "        self.fc1 = nn.Linear(200, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, 1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size2)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_size3)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        out = self.dropout(F.relu(self.bn1(self.fc1(seq))))\n",
    "        out = self.dropout(F.relu(self.bn2(self.fc2(out))))\n",
    "        out = self.dropout(F.relu(self.bn3(self.fc3(out))))\n",
    "        return self.fc4(out).squeeze()\n",
    "    \n",
    "    \n",
    "class MotifNet(nn.Module):\n",
    "    def __init__(self, hidden_size1, hidden_size2, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # conv parameters are fixed due to feature assemply process\n",
    "        # see dictionary variable _features\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=4,\n",
    "            out_channels=4,\n",
    "            kernel_size=3,\n",
    "            groups=4\n",
    "        )\n",
    "    \n",
    "        # input to linear: groups * (seq_len-2)\n",
    "        self.fc1 = nn.Linear(32, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, 1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size2)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        # input shape: (batch_size, seq_len, num_features)\n",
    "        out = self.conv(seq.transpose(1, 2))\n",
    "        \n",
    "        # input shape: (batch_size, groups, seq_len-2)\n",
    "        out = self.dropout(F.relu(self.bn1(self.fc1(out.view(out.shape[0], -1)))))\n",
    "        out = self.dropout(F.relu(self.bn2(self.fc2(out))))\n",
    "        return self.fc3(out).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b88b745-3768-4131-8b84-25552e46dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(seq_model, motif_model, loader, criterion, optims=None):\n",
    "    seq_epoch_loss, seq_num_correct, total = 0, 0, 0\n",
    "    motif_epoch_loss, motif_num_correct = 0, 0\n",
    "    seq_preds, motif_preds, lbls = [], [], []\n",
    "    \n",
    "    for seq, lbl in loader:\n",
    "        seq, lbl = seq.to(device), lbl.to(device)\n",
    "         \n",
    "        motif_scores = motif_model(seq[:, :, 22:])\n",
    "        seq_scores = seq_model(seq[:, :, :20].reshape(seq.shape[0], -1))\n",
    "            \n",
    "        motif_loss = criterion(motif_scores, lbl)\n",
    "        seq_loss = criterion(seq_scores, lbl)\n",
    "        \n",
    "        if optims is not None:\n",
    "            optims[0].zero_grad()\n",
    "            seq_loss.backward()\n",
    "            optims[0].step()\n",
    "            optims[1].zero_grad()\n",
    "            motif_loss.backward()\n",
    "            optims[1].step()\n",
    "        \n",
    "        seq_epoch_loss += seq_loss.item()\n",
    "        motif_epoch_loss += motif_loss.item()\n",
    "        seq_num_correct += ((seq_scores > 0) == lbl).sum().item()\n",
    "        motif_num_correct += ((motif_scores > 0) == lbl).sum().item()\n",
    "        total += seq.shape[0]\n",
    "        seq_preds.extend(seq_scores.detach().tolist())\n",
    "        motif_preds.extend(motif_scores.detach().tolist())\n",
    "        lbls.extend(lbl.detach().tolist())\n",
    "        \n",
    "    return (\n",
    "        seq_epoch_loss / total,\n",
    "        motif_epoch_loss / total,\n",
    "        seq_num_correct / total,\n",
    "        motif_num_correct / total,\n",
    "        roc_auc_score(lbls, seq_preds),\n",
    "        roc_auc_score(lbls, motif_preds)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec981f1-0377-451d-bfdc-30bd55424132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://github.com/pdxgx/pepsickle README for more info\n",
    "\n",
    "_features = {\n",
    "    'A': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,      6.0, 56.15265,   -0.495,  -2.4],\n",
    "    'C': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     5.07, 69.61701,    0.081,  -4.7],\n",
    "    'D': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     2.77, 70.04515,    9.573,  -4.5],\n",
    "    'E': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     3.22, 86.35615,    3.173,  -5.2],\n",
    "    'F': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   1,   0,     5.48,  119.722,   -0.370,  -4.9],\n",
    "    'G': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     5.97, 37.80307,    0.386,  -1.9],\n",
    "    'H': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   1,   0,     7.59, 97.94236,    2.029,  -4.4],\n",
    "    'I': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     6.02, 103.6644,   -0.528,  -6.6],\n",
    "    'K': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     9.74, 102.7783,    2.101,  -7.5],\n",
    "    'L': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     5.98, 102.7545,   -0.342,  -6.3],\n",
    "    'M': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     5.74,  103.928,   -0.324,  -6.1],\n",
    "    'N': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,   0,   0,     5.41, 76.56687,    2.354,  -4.7],\n",
    "    'P': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,   0,   0,      6.3, 71.24858,   -0.322,  -0.8],\n",
    "    'Q': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,   0,   0,     5.65, 88.62562,    2.176,  -5.5],\n",
    "    'R': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,   0,   0,    10.76, 110.5867,    4.383,  -6.9],\n",
    "    'S': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,   0,   1,     5.68, 55.89516,    0.936,  -4.6],\n",
    "    'T': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,   0,   1,      5.6,  72.0909,    0.853,  -5.1],\n",
    "    'V': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,   0,   0,     5.96, 86.28358,   -0.308,  -4.6],\n",
    "    'W': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,   1,   0,     5.89, 137.5186,    -0.27,  -4.8],\n",
    "    'Y': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,   1,   1,     5.66, 121.5862,    1.677,  -5.4],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42148192-6ec1-4ffa-8f86-2662575167dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and dev data\n",
    "train_seqs, train_lbl = read_data('../../data/n_train.csv')\n",
    "dev_seqs, dev_lbl = read_data('../../data/n_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac2678ed-9b3a-4d82-a339-e4d88d16183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(\n",
    "    config, checkpoint_dir=None, tr_seqs=None, tr_lbls=None, val_seqs=None, val_lbls=None\n",
    "):\n",
    "    \n",
    "    # create train and dev loader\n",
    "    train_data = CleavageDataset(tr_seqs, tr_lbls)\n",
    "    train_loader = DataLoader(train_data, batch_size=512, shuffle=True, collate_fn=collate_batch, num_workers=8)\n",
    "\n",
    "    dev_data = CleavageDataset(val_seqs, val_lbls)\n",
    "    dev_loader = DataLoader(dev_data, batch_size=512, shuffle=True, collate_fn=collate_batch, num_workers=8)\n",
    "    \n",
    "    \n",
    "    seq_model = SeqNet(\n",
    "        hidden_size1=config['seq_hidden1'],\n",
    "        hidden_size2=config['seq_hidden2'],\n",
    "        hidden_size3=config['seq_hidden3'],\n",
    "        dropout=config['seq_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    motif_model = MotifNet(\n",
    "        hidden_size1=config['motif_hidden1'],\n",
    "        hidden_size2=config['motif_hidden2'],\n",
    "        dropout=config['motif_dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    seq_optimizer = optim.Adam(seq_model.parameters(), lr=1e-3)\n",
    "    motif_optimizer = optim.Adam(motif_model.parameters(), lr=1e-3)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # normal train loop\n",
    "    for epoch in range(1, 100 + 1):\n",
    "        seq_model.train()\n",
    "        motif_model.train()\n",
    "        train_results = process(\n",
    "            seq_model, motif_model, train_loader, criterion, [seq_optimizer, motif_optimizer]\n",
    "        )\n",
    "\n",
    "        seq_model.eval()\n",
    "        motif_model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_results = process(seq_model, motif_model, dev_loader, criterion)\n",
    "        \n",
    "        with tune.checkpoint_dir(step=epoch) as checkpoint_dir:\n",
    "            seq_checkpoint_path = os.path.join(checkpoint_dir, \"seq_checkpoint.pt\")\n",
    "            motif_checkpoint_path = os.path.join(checkpoint_dir, \"motif_checkpoint.pt\")\n",
    "            torch.save(seq_model.state_dict(), seq_checkpoint_path)\n",
    "            torch.save(motif_model.state_dict(), motif_checkpoint_path)\n",
    "            \n",
    "        # metrics that will be reported back to main process\n",
    "        seq_reg_auc = regularized_auc(train_results[4], val_results[4])\n",
    "        motif_reg_auc = regularized_auc(train_results[5], val_results[5])\n",
    "        \n",
    "        tune.report(\n",
    "            seq_train_loss=train_results[0],\n",
    "            seq_val_loss=val_results[0],\n",
    "            motif_train_loss=train_results[1],\n",
    "            motif_val_loss=val_results[1],\n",
    "            seq_train_acc=train_results[2],\n",
    "            seq_val_acc=val_results[2],\n",
    "            motif_train_acc=train_results[3],\n",
    "            motif_val_acc=val_results[3],\n",
    "            seq_train_auc=train_results[4],\n",
    "            seq_val_auc=val_results[4],\n",
    "            motif_train_auc=train_results[5],\n",
    "            motif_val_auc=val_results[5],\n",
    "            seq_reg_auc=seq_reg_auc,\n",
    "            motif_reg_auc=motif_reg_auc,\n",
    "            summed_reg_auc=seq_reg_auc+motif_reg_auc\n",
    "        )\n",
    "        \n",
    "        # if both models are overfitting, stop the run\n",
    "        # otherwise continue the run to find optimal param combination afterwards\n",
    "        if seq_reg_auc == 0 and motif_reg_auc == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb5b724-1e03-45af-a4b1-f88d0065e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuneReporter(CLIReporter):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.num_terminated = 0\n",
    "\n",
    "    def should_report(self, trials, done=False):\n",
    "        \"\"\"Reports only on trial termination events.\"\"\"\n",
    "        old_num_terminated = self.num_terminated\n",
    "        self.num_terminated = len([t for t in trials if t.status == \"TERMINATED\"])\n",
    "        return self.num_terminated > old_num_terminated\n",
    "    \n",
    "    def report(self, trials, done, *sys_info):\n",
    "        print(self._progress_str(trials, done, *sys_info))\n",
    "    \n",
    "metrics = [\n",
    "    'seq_train_loss', 'motif_train_loss',\n",
    "    'seq_val_loss', 'motif_val_loss',\n",
    "    'seq_train_acc', 'motif_train_acc',\n",
    "    'seq_val_acc', 'motif_val_acc',\n",
    "    'seq_train_auc', 'motif_train_auc',\n",
    "    'seq_val_auc', 'motif_val_auc',\n",
    "    'seq_reg_auc', 'motif_reg_auc',\n",
    "    'summed_reg_auc',\n",
    "]\n",
    "\n",
    "reporter = TuneReporter()\n",
    "for metric in metrics:\n",
    "    reporter.add_metric_column(metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5cd2fff-19cc-41dc-9e77-ab39a81c5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'seq_hidden1': tune.randint(120, 201),\n",
    "    'seq_hidden2': tune.randint(60, 141),\n",
    "    'seq_hidden3': tune.randint(20, 81),\n",
    "    'seq_dropout': tune.quniform(0.2, 0.36, 0.02),\n",
    "    'motif_hidden1': tune.randint(120, 201),\n",
    "    'motif_hidden2': tune.randint(20, 101),\n",
    "    'motif_dropout': tune.quniform(0.1, 0.26, 0.02),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9daffc-8f25-412c-824b-40852716f4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '../../params/n_term/pepsickle/'\n",
    "experiment = 'search'\n",
    "num_samples = 30\n",
    "\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(\n",
    "        train, tr_seqs=train_seqs, tr_lbls=train_lbl, val_seqs=dev_seqs, val_lbls=dev_lbl\n",
    "    ),\n",
    "    name=experiment,\n",
    "    config=search_space,\n",
    "    sync_config=tune.SyncConfig(syncer=None),\n",
    "    num_samples=num_samples,\n",
    "    scheduler=ASHAScheduler(\n",
    "        metric='summed_reg_auc',\n",
    "        mode='max',\n",
    "        reduction_factor=2,\n",
    "        grace_period=4\n",
    "    ),\n",
    "    progress_reporter=reporter,\n",
    "    local_dir=path,\n",
    "    keep_checkpoints_num=None, # keep all checkpoints\n",
    "    checkpoint_score_attr='summed_reg_auc',\n",
    "    resume='AUTO',\n",
    "    resources_per_trial={'cpu': 16, 'gpu': 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f668a-f080-486a-87c6-e26766264a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
